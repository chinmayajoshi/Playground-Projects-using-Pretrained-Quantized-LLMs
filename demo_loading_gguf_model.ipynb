{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library and Model Credits:<br>\n",
    "- llama.cpp by GGML ([repo](https://github.com/ggerganov/llama.cpp))<br>\n",
    "- Python Bindings for llama.cpp ([repo](https://github.com/abetlen/llama-cpp-python))\n",
    "- Quantized Model from TheBloke at HuggingFace ([model](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading GGUF Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpath = r'C:/Users/chinm/.cache/lm-studio/models/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/mistral-7b-instruct-v0.1.Q5_K_M.gguf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from C:/Users/chinm/.cache/lm-studio/models/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/mistral-7b-instruct-v0.1.Q5_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4892.99 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    81.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.name': 'mistralai_mistral-7b-instruct-v0.1', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '17', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "\n",
    "llm = Llama(model_path=mpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asking a question to the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = '''\n",
    "List the top 5 most powerful wizards in the Harry Potter universe and give a single line explanation for each character's postion in the list.\n",
    "Take a deep breath and think step-by-step before making the list.\n",
    "\n",
    "List:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    6949.91 ms\n",
      "llama_print_timings:      sample time =      34.40 ms /   157 runs   (    0.22 ms per token,  4564.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6949.80 ms /    58 tokens (  119.82 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:        eval time =   30409.08 ms /   156 runs   (  194.93 ms per token,     5.13 tokens per second)\n",
      "llama_print_timings:       total time =   37848.84 ms /   214 tokens\n"
     ]
    }
   ],
   "source": [
    "%timeit \n",
    "\n",
    "output = llm(\n",
    "    question, # Prompt\n",
    "    max_tokens= None, # Generate up to [max_tokens] tokens, set to None to generate up to the end of the context window\n",
    "    echo=True, # Echo the prompt back in the output\n",
    "    temperature=0 # The temperature parameter (higher for more \"creative\" or \"out of distribution\" output)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-3363195a-49da-46a9-8b5f-9359c3878753',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1713424831,\n",
       " 'model': 'C:/Users/chinm/.cache/lm-studio/models/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/mistral-7b-instruct-v0.1.Q5_K_M.gguf',\n",
       " 'choices': [{'text': \"\\nList the top 5 most powerful wizards in the Harry Potter universe and give a single line explanation for each character's postion in the list.\\nTake a deep breath and think step-by-step before making the list.\\n\\nList:\\n1. Albus Dumbledore - He is the most powerful wizard of all time, with immense knowledge and wisdom.\\n2. Severus Snape - He is one of the most skilled potion masters in the universe, with a deep understanding of dark magic.\\n3. Voldemort - Despite his evil intentions, he possesses immense magical power and is considered one of the most powerful wizards in the universe.\\n4. Gilderoy Lockhart - He is a master of charms and has an extensive knowledge of magical history.\\n5. Minerva McGonagall - She is a skilled duelist and has a deep understanding of magical theory, making her one of the most powerful witches in the universe.\",\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 58, 'completion_tokens': 156, 'total_tokens': 214}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List the top 5 most powerful wizards in the Harry Potter universe and give a single line explanation for each character's postion in the list.\n",
      "Take a deep breath and think step-by-step before making the list.\n",
      "\n",
      "List:\n",
      "1. Albus Dumbledore - He is the most powerful wizard of all time, with immense knowledge and wisdom.\n",
      "2. Severus Snape - He is one of the most skilled potion masters in the universe, with a deep understanding of dark magic.\n",
      "3. Voldemort - Despite his evil intentions, he possesses immense magical power and is considered one of the most powerful wizards in the universe.\n",
      "4. Gilderoy Lockhart - He is a master of charms and has an extensive knowledge of magical history.\n",
      "5. Minerva McGonagall - She is a skilled duelist and has a deep understanding of magical theory, making her one of the most powerful witches in the universe.\n"
     ]
    }
   ],
   "source": [
    "print(output['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6949.91 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /    15 runs   (    0.21 ms per token,  4671.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     948.70 ms /    10 tokens (   94.87 ms per token,    10.54 tokens per second)\n",
      "llama_print_timings:        eval time =    2742.99 ms /    14 runs   (  195.93 ms per token,     5.10 tokens per second)\n",
      "llama_print_timings:       total time =    3742.64 ms /    24 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-f326f282-4a6a-415c-ba1b-d5e6791e9ba9',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1713424869,\n",
       " 'model': 'C:/Users/chinm/.cache/lm-studio/models/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/mistral-7b-instruct-v0.1.Q5_K_M.gguf',\n",
       " 'choices': [{'text': '\\nAlbus Percival Wulfric Brian Dumbledore',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 11, 'completion_tokens': 14, 'total_tokens': 25}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit \n",
    "\n",
    "llm('What is the full name of Dumbledore?', temperature=0, max_tokens=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Same Prompt with different Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temperature=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6949.91 ms\n",
      "llama_print_timings:      sample time =      39.98 ms /   170 runs   (    0.24 ms per token,  4251.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1267.67 ms /    11 tokens (  115.24 ms per token,     8.68 tokens per second)\n",
      "llama_print_timings:        eval time =   32426.19 ms /   169 runs   (  191.87 ms per token,     5.21 tokens per second)\n",
      "llama_print_timings:       total time =   34279.71 ms /   180 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-30fb87fe-2bbc-4374-a90f-8e64de4602b6',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1713424873,\n",
       " 'model': 'C:/Users/chinm/.cache/lm-studio/models/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/mistral-7b-instruct-v0.1.Q5_K_M.gguf',\n",
       " 'choices': [{'text': '.\\n\\n1. Zephyrus - A name inspired by the Greek god of the west wind, this name is perfect for someone who loves adventure and exploration. It has a modern and unique sound to it, making it stand out in a crowd.\\n2. Elysium - This name comes from the mythical land of eternal happiness and peace, and is perfect for someone who wants to live life to the fullest. It has a regal and sophisticated sound to it, making it ideal for someone with a refined taste.\\n3. Orion - Named after the famous constellation in the night sky, this name is perfect for someone who loves astronomy and science. It has a strong and powerful sound to it, making it ideal for someone who wants to make a big impact on the world.',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 12, 'completion_tokens': 169, 'total_tokens': 181}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit \n",
    "\n",
    "op1 = llm('Give me 3 novel and new names from that universe', temperature=0, max_tokens=None)\n",
    "op1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "1. Zephyrus - A name inspired by the Greek god of the west wind, this name is perfect for someone who loves adventure and exploration. It has a modern and unique sound to it, making it stand out in a crowd.\n",
      "2. Elysium - This name comes from the mythical land of eternal happiness and peace, and is perfect for someone who wants to live life to the fullest. It has a regal and sophisticated sound to it, making it ideal for someone with a refined taste.\n",
      "3. Orion - Named after the famous constellation in the night sky, this name is perfect for someone who loves astronomy and science. It has a strong and powerful sound to it, making it ideal for someone who wants to make a big impact on the world.\n"
     ]
    }
   ],
   "source": [
    "print(op1['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature=1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6949.91 ms\n",
      "llama_print_timings:      sample time =      46.41 ms /   256 runs   (    0.18 ms per token,  5516.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   50589.11 ms /   256 runs   (  197.61 ms per token,     5.06 tokens per second)\n",
      "llama_print_timings:       total time =   51537.36 ms /   257 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-e92506cc-a463-4b0d-ac81-3edb266c4e43',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1713424907,\n",
       " 'model': 'C:/Users/chinm/.cache/lm-studio/models/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/mistral-7b-instruct-v0.1.Q5_K_M.gguf',\n",
       " 'choices': [{'text': '.\\n\\nGive me three brand new characters to add to this world, including their name, backstory, and role in the story:\\n\\n1) Name: Kael\\nBackstory: Kael was once a powerful mage, known throughout the realm for his mastery of magic. However, after a tragic event caused him to lose everything he had, Kael became obsessed with finding a way to bring back what he had lost. He dedicated his life to studying the arcane arts and delved deep into forbidden knowledge.\\n2) Name: Lena\\nBackstory: Lena was a skilled warrior, trained from a young age in the ways of combat. However, she struggled to come to terms with her past and often felt lost without direction in life. Her travels took her on a journey to find purpose and meaning beyond just fighting.\\n3) Name: Marcus\\nRole: Marcus is an enigmatic figure who has always remained on the fringes of society. He has always been fascinated by technology and has spent years studying and experimenting with new inventions. However, his work has often put him at odds with those in power who fear what his creations might do if they fell into the wrong hands.',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 12, 'completion_tokens': 255, 'total_tokens': 267}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit \n",
    "\n",
    "op2 = llm('Give me 3 novel and new names from that universe', temperature=1.2, max_tokens=None)\n",
    "op2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "Give me three brand new characters to add to this world, including their name, backstory, and role in the story:\n",
      "\n",
      "1) Name: Kael\n",
      "Backstory: Kael was once a powerful mage, known throughout the realm for his mastery of magic. However, after a tragic event caused him to lose everything he had, Kael became obsessed with finding a way to bring back what he had lost. He dedicated his life to studying the arcane arts and delved deep into forbidden knowledge.\n",
      "2) Name: Lena\n",
      "Backstory: Lena was a skilled warrior, trained from a young age in the ways of combat. However, she struggled to come to terms with her past and often felt lost without direction in life. Her travels took her on a journey to find purpose and meaning beyond just fighting.\n",
      "3) Name: Marcus\n",
      "Role: Marcus is an enigmatic figure who has always remained on the fringes of society. He has always been fascinated by technology and has spent years studying and experimenting with new inventions. However, his work has often put him at odds with those in power who fear what his creations might do if they fell into the wrong hands.\n"
     ]
    }
   ],
   "source": [
    "print(op2['choices'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_gguf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
